{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuV5E9I8qmQ9A0uNivxT8c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Installing tensorlfow for gpu"],"metadata":{"id":"9VkDP_61PCTF"}},{"cell_type":"code","metadata":{"id":"iMjhXQIsAsJ_","outputId":"f78099d2-38a5-4eee-8138-7e10fd0836cc","colab":{"base_uri":"https://localhost:8080/","height":948}},"source":["!pip install tensorflow-gpu==2.1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 18kB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.9.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.2.2)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 49.4MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (3.10.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.1.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.27.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.11.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.8.1)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (3.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.12.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.34.2)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 58.4MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.17.5)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2.21.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.7.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.2.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (45.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.0.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1) (2.8.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.3.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2.8)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.2.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.4.8)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","Successfully installed tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","source":["importing required python libraries"],"metadata":{"id":"6JSyJSv7PGkY"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import sys\n","import h5py\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import tables\n","from sklearn import preprocessing\n","import gdown\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, Input\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import MaxPooling1D\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n","from tensorflow.keras.layers import Flatten, GlobalAveragePooling1D, GlobalMaxPooling1D\n","from sklearn.utils import class_weight"],"metadata":{"id":"RNNFfxLuwyy5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Setting data file paths and model weight files "],"metadata":{"id":"NiUDu5BEPgm6"}},{"cell_type":"code","source":["\n","FILT_FILE_PATH = 'TUH_filt.hdf5'\n","\n","if not os.path.exists(FILT_FILE_PATH):\n","    gdown.download('https://drive.google.com/uc?id=1-NP_r_VxjR7np9n0tswqguTB5Vps0pO5', \n","                   './'+FILE_PATH, quiet=False)\n"],"metadata":{"id":"j82lDqPmw4Wy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining function for getting data files and transforming into desired format for processing data into model\n","\n","\n","*   splitting data into train, validation and test dataset , train set 80 % , validation set = 10 % and Test Set = 10 %\n","*   Printing shape of the data for each sample set\n","\n","\n","\n"],"metadata":{"id":"Qv6-mpxYQ3tR"}},{"cell_type":"code","metadata":{"id":"ltQ-DJS7CJfj","outputId":"b4230532-95e7-46ce-d06a-41052ebee5a1","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["\n","TEST_SIZE = 0.1\n","RANDOM_STATE = 0\n","\n","def make_data(data_lists, data_type, filepath):\n","  data_dict = {}\n","  h5file = tables.open_file(filepath, mode=\"r+\")\n","  for group_type in data_lists:\n","    key_list = data_lists[group_type]\n","    for i, part_id in enumerate(key_list):\n","      if i == 0:\n","        data = h5file.get_node('/'+part_id+'/'+data_type)[:]\n","      else:\n","        data = np.concatenate([data, h5file.get_node('/'+part_id+'/'+data_type)[:]])\n","    data_dict[group_type] = data\n","  return data_dict\n","\n","def load_and_prep(FILE_PATH):\n","  f = h5py.File(FILE_PATH, 'r')\n","  key_list = list(f.keys())\n","\n","  train_list, test_list = train_test_split(key_list, test_size=TEST_SIZE, \n","                                          random_state=RANDOM_STATE)\n","  train_list, val_list = train_test_split(train_list, test_size=TEST_SIZE, \n","                                          random_state=RANDOM_STATE)\n","  data_lists = {'train': train_list, \n","                'test': test_list,\n","                'val': val_list}\n","\n","  data_x_dict = make_data(data_lists, 'Data_x', FILE_PATH)\n","  X_train = data_x_dict['train']\n","  X_val = data_x_dict['val']\n","  X_test = data_x_dict['test']\n","\n","  data_y_dict = make_data(data_lists, 'Data_y', FILE_PATH)\n","  y_train = data_y_dict['train']\n","  y_val = data_y_dict['val']\n","  y_test = data_y_dict['test']\n","\n","  le = preprocessing.LabelEncoder()\n","  y_train = le.fit_transform(y_train)\n","  y_val = le.transform(y_val)\n","  y_test = le.transform(y_test)\n","\n","  print(X_train.shape)\n","  print(X_val.shape)\n","  print(X_test.shape)\n","\n","  print(y_train.shape)\n","  print(y_val.shape)\n","  print(y_test.shape)\n","\n","  return X_train, X_val, X_test, y_train, y_val, y_test\n","\n","X_train_filt, X_val_filt, X_test_filt, y_train_filt, y_val_filt, y_test_filt = load_and_prep(FILT_FILE_PATH)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(16764, 512, 22)\n","(2421, 512, 22)\n","(2814, 512, 22)\n","(16764,)\n","(2421,)\n","(2814,)\n"],"name":"stdout"}]},{"cell_type":"markdown","source":["As we can see from above output, our dataframe is three dimensional.\n","different data windows (each with a class label in the y array)\n","a single data point (512 being the length of the window)\n","The various channels\n","As an example, let's take a look at one of the windows in one of the channels."],"metadata":{"id":"OgFW7OCnQRpc"}},{"cell_type":"code","metadata":{"id":"4komZ3-dHp_G"},"source":["\n","\n","clear_session()\n","model = Sequential()\n","# this just tells the model what input shape to expect\n","model.add(Input(shape=X_train_filt.shape[1:]))\n","for i in range(2):\n","  model.add(Conv1D(filters=64,\n","                  kernel_size=3,\n","                  padding=\"same\",\n","                  activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.add(MaxPooling1D(pool_size=3, # size of the window\n","                       strides=2,   # factor to downsample\n","                       padding='same'))"],"metadata":{"id":"ch7i9k6TxErd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(2):\n","  model.add(Conv1D(filters=128,\n","                  kernel_size=3,\n","                  padding=\"same\",\n","                  activation='relu'))"],"metadata":{"id":"vdxl1TsdxGcr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Adding flatten layer to the model"],"metadata":{"id":"JqZd0aOiSRoW"}},{"cell_type":"code","source":["\n","model.add(Flatten())"],"metadata":{"id":"9mpBwPVLxI1N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" \n","\n","*   Adding dense layer to the model.\n","*   Adding final dense layer with sigmoid as activation function.\n","\n","*   Compiling the model\n","*   Printing summary of the model\n","\n","\n","\n","\n"],"metadata":{"id":"y8VDldngSVQG"}},{"cell_type":"code","metadata":{"id":"FXcBLNPoQHG9","outputId":"316d55d3-3b32-4c6c-9a7e-3aee6446caab","colab":{"base_uri":"https://localhost:8080/","height":446}},"source":["\n","\n","model.add(Dense(units=100,\n","                activation='relu'))\n","\n","model.add(Dense(units=1,\n","                activation='sigmoid'))\n","\n","model.compile(optimizer=Adam(0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy', 'AUC', 'Recall', 'Precision'])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d (Conv1D)              (None, 512, 64)           4288      \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 512, 64)           12352     \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 256, 64)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 256, 128)          24704     \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 256, 128)          49280     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 100)               3276900   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 101       \n","=================================================================\n","Total params: 3,367,625\n","Trainable params: 3,367,625\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","source":[],"metadata":{"id":"xf3yslD8xN6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining compact function which do all of the following in one step\n","\n","\n","*   Took Train data sample as input \n","*   Return final model after adding all the required layers\n","\n","\n","*   1D Convolution\n","*   Max pooling \n","\n","*   Fltten layer\n","*   Dense Layer\n","\n","*   Compiling the model\n","*   Printing summary of the model\n"],"metadata":{"id":"Si_hE71DTuGT"}},{"cell_type":"code","metadata":{"id":"a4WD7dr9RYvJ","outputId":"c071fabb-7a14-4cf8-c7cf-0d89469f14bd","colab":{"base_uri":"https://localhost:8080/","height":446}},"source":["# Returns a short sequential model\n","def create_model(input_shape, flatten=False):\n","  clear_session()\n","  model = Sequential()\n","\n","  # this just tells the model what input shape to expect\n","  model.add(Input(shape=input_shape[1:]))\n","  for i in range(2):\n","    model.add(Conv1D(filters=64,\n","                    kernel_size=3,\n","                    padding=\"same\",\n","                    activation='relu'))\n","    \n","  model.add(MaxPooling1D(pool_size=3, # size of the window\n","                       strides=2,   # factor to downsample\n","                       padding='same'))\n","  \n","  for i in range(2):\n","    model.add(Conv1D(filters=128,\n","                    kernel_size=3,\n","                    padding=\"same\",\n","                    activation='relu'))\n","  if flatten:\n","    model.add(Flatten())\n","  else:\n","    model.add(GlobalAveragePooling1D())\n","\n","  model.add(Dense(units=64,\n","                  activation='relu'))\n","\n","  model.add(Dense(units=1,\n","                  activation='sigmoid'))\n","\n","  model.compile(optimizer=Adam(0.001),\n","                loss='binary_crossentropy',\n","                metrics=['accuracy', 'AUC', 'Recall', 'Precision'])\n","\n","  return model\n","\n","clear_session()\n","# Create a basic model instance\n","model = create_model(X_train_filt.shape)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d (Conv1D)              (None, 512, 64)           4288      \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 512, 64)           12352     \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 256, 64)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 256, 128)          24704     \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 256, 128)          49280     \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                8256      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 98,945\n","Trainable params: 98,945\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","source":["Defining call back functions for early stopping of the model to get best models weights during training"],"metadata":{"id":"PcvMdOGGSuY6"}},{"cell_type":"code","metadata":{"id":"rEEEZTwNSuyR"},"source":["\n","\n","def create_callbacks(best_model_filepath, tensorboard_logs_filepath):\n","\n","  callback_checkpoint = ModelCheckpoint(filepath=best_model_filepath,\n","                                        monitor='val_loss',\n","                                        verbose=0,\n","                                        save_weights_only=True,\n","                                        save_best_only=True)\n","  \n","  callback_early_stopping = EarlyStopping(monitor='val_loss',\n","                                          patience=10, \n","                                          verbose=1)\n","  \n","  callback_tensorboard = TensorBoard(log_dir=tensorboard_logs_filepath,\n","                                     histogram_freq=0,\n","                                     write_graph=False)\n","  \n","  callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                                         factor=0.1,\n","                                         min_lr=1e-4,\n","                                         patience=0,\n","                                         verbose=1)\n","  \n","  return [callback_checkpoint, callback_early_stopping,\n","          callback_tensorboard, callback_reduce_lr]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zEb_UhBRUO3e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining paths where model model weights needs to be stored\n","\n","*   Defining hyperparameters like batch size, no. of epochs\n","*   Training the model\n","\n"],"metadata":{"id":"tA-roww_UPfo"}},{"cell_type":"code","metadata":{"id":"CmhRHVnURDoU","outputId":"1c4a13b5-1000-4752-c1dd-679290dfa4fd","colab":{"base_uri":"https://localhost:8080/","height":394}},"source":["\n","\n","EPOCHS = 20\n","BATCH_SIZE = 64\n","best_model_filepath = \"CNN1D_Model.ckpt\"\n","tensorboard_logs_filepath = \"./CNN1D_logs/\"\n","\n","# calculate the class weights\n","class_weights = class_weight.compute_class_weight('balanced',\n","                                                  np.unique(y_train_filt),\n","                                                  y_train_filt)\n","\n","history_1D = model.fit(X_train_filt, \n","                       y_train_filt,\n","                       batch_size=BATCH_SIZE, \n","                       epochs=EPOCHS,\n","                       validation_data = (X_val_filt, y_val_filt),\n","                       callbacks= create_callbacks(best_model_filepath, \n","                                                   tensorboard_logs_filepath),\n","                       class_weight = class_weights,\n","                       verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 16764 samples, validate on 2421 samples\n","Epoch 1/20\n","16764/16764 [==============================] - 4s 231us/sample - loss: 0.1140 - accuracy: 0.9772 - AUC: 0.8452 - Recall: 0.5566 - Precision: 0.7687 - val_loss: 0.0980 - val_accuracy: 0.9727 - val_AUC: 0.9726 - val_Recall: 0.7328 - val_Precision: 1.0000\n","Epoch 2/20\n","16764/16764 [==============================] - 3s 157us/sample - loss: 0.0464 - accuracy: 0.9880 - AUC: 0.9563 - Recall: 0.7608 - Precision: 0.9017 - val_loss: 0.0689 - val_accuracy: 0.9818 - val_AUC: 0.9767 - val_Recall: 0.8300 - val_Precision: 0.9903\n","Epoch 3/20\n","16448/16764 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9888 - AUC: 0.9636 - Recall: 0.7704 - Precision: 0.9167\n","Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","16764/16764 [==============================] - 3s 162us/sample - loss: 0.0437 - accuracy: 0.9888 - AUC: 0.9640 - Recall: 0.7687 - Precision: 0.9181 - val_loss: 0.0822 - val_accuracy: 0.9777 - val_AUC: 0.9740 - val_Recall: 0.7814 - val_Precision: 1.0000\n","Epoch 4/20\n","16384/16764 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9904 - AUC: 0.9728 - Recall: 0.7906 - Precision: 0.9438\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001.\n","16764/16764 [==============================] - 3s 158us/sample - loss: 0.0359 - accuracy: 0.9905 - AUC: 0.9729 - Recall: 0.7927 - Precision: 0.9431 - val_loss: 0.0830 - val_accuracy: 0.9769 - val_AUC: 0.9731 - val_Recall: 0.7733 - val_Precision: 1.0000\n","Epoch 5/20\n","16764/16764 [==============================] - 3s 157us/sample - loss: 0.0350 - accuracy: 0.9906 - AUC: 0.9771 - Recall: 0.7927 - Precision: 0.9467 - val_loss: 0.0841 - val_accuracy: 0.9777 - val_AUC: 0.9722 - val_Recall: 0.7814 - val_Precision: 1.0000\n","Epoch 6/20\n","16764/16764 [==============================] - 3s 156us/sample - loss: 0.0345 - accuracy: 0.9908 - AUC: 0.9769 - Recall: 0.7974 - Precision: 0.9470 - val_loss: 0.0797 - val_accuracy: 0.9798 - val_AUC: 0.9710 - val_Recall: 0.8016 - val_Precision: 1.0000\n","Epoch 7/20\n","16764/16764 [==============================] - 3s 157us/sample - loss: 0.0336 - accuracy: 0.9909 - AUC: 0.9767 - Recall: 0.7974 - Precision: 0.9506 - val_loss: 0.0836 - val_accuracy: 0.9785 - val_AUC: 0.9696 - val_Recall: 0.7895 - val_Precision: 1.0000\n","Epoch 00007: early stopping\n"],"name":"stdout"}]}]}